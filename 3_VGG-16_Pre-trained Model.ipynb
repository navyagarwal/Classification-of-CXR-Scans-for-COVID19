{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#IMPORTING PACKAGES\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.layers import AveragePooling2D, Dense, Flatten, Dropout\nfrom keras.models import Model\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-22T18:12:37.121883Z","iopub.execute_input":"2022-07-22T18:12:37.122329Z","iopub.status.idle":"2022-07-22T18:12:37.129252Z","shell.execute_reply.started":"2022-07-22T18:12:37.122269Z","shell.execute_reply":"2022-07-22T18:12:37.128357Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"normal_path = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images\"\nviral_path = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/images\"\ncovid_path = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images\"","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:24.266985Z","iopub.execute_input":"2022-07-22T17:30:24.267600Z","iopub.status.idle":"2022-07-22T17:30:24.275259Z","shell.execute_reply.started":"2022-07-22T17:30:24.267567Z","shell.execute_reply":"2022-07-22T17:30:24.274328Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#listdir returns a list of all the files in the mentioned directory\nfilenames = os.listdir(normal_path) + os.listdir(viral_path) + os.listdir(covid_path) ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:24.276595Z","iopub.execute_input":"2022-07-22T17:30:24.277098Z","iopub.status.idle":"2022-07-22T17:30:24.734711Z","shell.execute_reply.started":"2022-07-22T17:30:24.277062Z","shell.execute_reply":"2022-07-22T17:30:24.733767Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 0 -> Normal\n# 1 -> Viral Pneumonia\n# 2 -> COVID-19\n\n#Iterating through all the files and appending their label to 'categories' list\ncategories = []\npaths = []\nfor filename in filenames:\n    if \"Normal\" in filename:\n        categories.append('normal')\n        paths.append(normal_path + '/' + filename)\n    if \"Viral Pneumonia\" in filename:\n        categories.append('viral pneumonia')\n        paths.append(viral_path + '/' + filename)\n    if \"COVID\" in filename:\n        categories.append('covid')\n        paths.append(covid_path + '/' + filename)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:24.738906Z","iopub.execute_input":"2022-07-22T17:30:24.740881Z","iopub.status.idle":"2022-07-22T17:30:24.755709Z","shell.execute_reply.started":"2022-07-22T17:30:24.740851Z","shell.execute_reply":"2022-07-22T17:30:24.754783Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Creating a dataframe with two columns, one containing the path of the XRay scanned image\n#And the other column containing its label\ndf = pd.DataFrame({\n    'File Path' : paths,\n    'Category' : categories\n})","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:24.759020Z","iopub.execute_input":"2022-07-22T17:30:24.759338Z","iopub.status.idle":"2022-07-22T17:30:24.770665Z","shell.execute_reply.started":"2022-07-22T17:30:24.759311Z","shell.execute_reply":"2022-07-22T17:30:24.769731Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#A sample image to showcase that our code works fine\n#Reading the image with opencv and plotting the image using matplotlib\nimg = cv2.imread(df['File Path'][2000])\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:24.771727Z","iopub.execute_input":"2022-07-22T17:30:24.772524Z","iopub.status.idle":"2022-07-22T17:30:25.012732Z","shell.execute_reply.started":"2022-07-22T17:30:24.772445Z","shell.execute_reply":"2022-07-22T17:30:25.011814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Splitting into training and testing data\n# train_test_split parameters:\n# -> dataframe (or input data)\n# -> test_size -> 1/4th of the input data is used as test and validation data\n# -> random_state -> used to control randomness of our shuffle \n# -> stratify -> splits the data into strata(or groups) based on a particular parameter\ntrain_data , test_valid_data = train_test_split(df, test_size=0.25, random_state = 42, \n                                                shuffle=True, stratify=df['Category'])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:25.014321Z","iopub.execute_input":"2022-07-22T17:30:25.014996Z","iopub.status.idle":"2022-07-22T17:30:25.042686Z","shell.execute_reply.started":"2022-07-22T17:30:25.014956Z","shell.execute_reply":"2022-07-22T17:30:25.041877Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#resest_index -> normalises the indices of dataframe such that they start with 0\ntrain_data = train_data.reset_index(drop=True)\ntest_valid_data = test_valid_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:25.045876Z","iopub.execute_input":"2022-07-22T17:30:25.046177Z","iopub.status.idle":"2022-07-22T17:30:25.052224Z","shell.execute_reply.started":"2022-07-22T17:30:25.046152Z","shell.execute_reply":"2022-07-22T17:30:25.051301Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Splitting testing data into validation and testing data\ntest_data, valid_data = train_test_split(test_valid_data, test_size=0.5, random_state = 42, shuffle=True, stratify=test_valid_data['Category'])\ntest_data = test_data.reset_index(drop=True)\nvalid_data = valid_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:25.055546Z","iopub.execute_input":"2022-07-22T17:30:25.055805Z","iopub.status.idle":"2022-07-22T17:30:25.068297Z","shell.execute_reply.started":"2022-07-22T17:30:25.055780Z","shell.execute_reply":"2022-07-22T17:30:25.067355Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# ImageDataGenerator -> Generates batches of tensor image data with real-time data augmentation\n# rescale -> divide by 255 to normalise images","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:47.791641Z","iopub.execute_input":"2022-07-22T17:30:47.792291Z","iopub.status.idle":"2022-07-22T17:30:47.796391Z","shell.execute_reply.started":"2022-07-22T17:30:47.792256Z","shell.execute_reply":"2022-07-22T17:30:47.795446Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:49.209725Z","iopub.execute_input":"2022-07-22T17:30:49.210372Z","iopub.status.idle":"2022-07-22T17:30:49.216241Z","shell.execute_reply.started":"2022-07-22T17:30:49.210336Z","shell.execute_reply":"2022-07-22T17:30:49.215065Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# flow_from_dataframe method -> Takes the dataframe as input and generates batches of normalised and augmented data\n# class_mode -> if 'categorical', the y_col parameter contains the target labels/classes\n# x_col -> column in dataframe that contains file paths of images\n# target_size -> size to which all images are resized","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:50.026374Z","iopub.execute_input":"2022-07-22T17:30:50.027058Z","iopub.status.idle":"2022-07-22T17:30:50.031557Z","shell.execute_reply.started":"2022-07-22T17:30:50.027019Z","shell.execute_reply":"2022-07-22T17:30:50.030417Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_gen = train_data_gen.flow_from_dataframe(\n    train_data, \n    x_col='File Path',\n    y_col='Category',\n    target_size=(224,224),\n    class_mode='categorical',\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:30:51.131999Z","iopub.execute_input":"2022-07-22T17:30:51.132734Z","iopub.status.idle":"2022-07-22T17:31:12.575659Z","shell.execute_reply.started":"2022-07-22T17:30:51.132670Z","shell.execute_reply":"2022-07-22T17:31:12.574643Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"valid_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\nvalid_gen = valid_data_gen.flow_from_dataframe(\n    valid_data, \n    x_col='File Path',\n    y_col='Category',\n    target_size=(224,224),\n    class_mode='categorical',\n    batch_size=32\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:31:12.577414Z","iopub.execute_input":"2022-07-22T17:31:12.578332Z","iopub.status.idle":"2022-07-22T17:31:16.093204Z","shell.execute_reply.started":"2022-07-22T17:31:12.578293Z","shell.execute_reply":"2022-07-22T17:31:16.092102Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# instantiating a VGG16 model whose weights have been pretrained using imagenet data\n# include_top -> leaving out the top layers of the model because we want the model to work images of varying sizes","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:35:53.464818Z","iopub.execute_input":"2022-07-22T17:35:53.465234Z","iopub.status.idle":"2022-07-22T17:35:53.470084Z","shell.execute_reply.started":"2022-07-22T17:35:53.465178Z","shell.execute_reply":"2022-07-22T17:35:53.468841Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"base_model = VGG16(input_shape=(224,224,3), weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:31:31.601762Z","iopub.execute_input":"2022-07-22T17:31:31.602113Z","iopub.status.idle":"2022-07-22T17:31:35.663108Z","shell.execute_reply.started":"2022-07-22T17:31:31.602083Z","shell.execute_reply":"2022-07-22T17:31:35.661875Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Customisations to VGG16:\n# Adding Pooling and Flatten layers to the model\n# Adding 1 hidden layer where we chose the activation function as Rectified Linear Unit\n# Adding a Dropout layer to prevent overfitting of model\n# Finaly using a softmax in our output layer","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:36:04.171851Z","iopub.execute_input":"2022-07-22T17:36:04.172663Z","iopub.status.idle":"2022-07-22T17:36:04.177495Z","shell.execute_reply.started":"2022-07-22T17:36:04.172624Z","shell.execute_reply":"2022-07-22T17:36:04.176383Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False\n\nhead_model = base_model.output\nhead_model = AveragePooling2D()(head_model)\nhead_model = Flatten()(head_model)\nhead_model = Dense(128, activation=\"relu\")(head_model)\nhead_model = Dropout(0.2)(head_model)\nhead_model = Dense(3, activation='softmax')(head_model)\n\nmodel = Model(inputs=base_model.input, outputs=head_model)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:36:05.515563Z","iopub.execute_input":"2022-07-22T17:36:05.516245Z","iopub.status.idle":"2022-07-22T17:36:05.553020Z","shell.execute_reply.started":"2022-07-22T17:36:05.516206Z","shell.execute_reply":"2022-07-22T17:36:05.552129Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:36:09.442700Z","iopub.execute_input":"2022-07-22T17:36:09.443699Z","iopub.status.idle":"2022-07-22T17:36:09.452492Z","shell.execute_reply.started":"2022-07-22T17:36:09.443652Z","shell.execute_reply":"2022-07-22T17:36:09.451460Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:36:13.731373Z","iopub.execute_input":"2022-07-22T17:36:13.732064Z","iopub.status.idle":"2022-07-22T17:36:13.746944Z","shell.execute_reply.started":"2022-07-22T17:36:13.732026Z","shell.execute_reply":"2022-07-22T17:36:13.745839Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory = model.fit_generator(train_gen, epochs=epochs, validation_data=valid_gen, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:36:23.451504Z","iopub.execute_input":"2022-07-22T17:36:23.451853Z","iopub.status.idle":"2022-07-22T18:03:19.761387Z","shell.execute_reply.started":"2022-07-22T17:36:23.451822Z","shell.execute_reply":"2022-07-22T18:03:19.760308Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#Saving our model\nmodel.save('Covid.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:04:53.231258Z","iopub.execute_input":"2022-07-22T18:04:53.232016Z","iopub.status.idle":"2022-07-22T18:04:53.358785Z","shell.execute_reply.started":"2022-07-22T18:04:53.231977Z","shell.execute_reply":"2022-07-22T18:04:53.357725Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# MODEL ANALYSIS","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:05:08.387718Z","iopub.execute_input":"2022-07-22T18:05:08.388063Z","iopub.status.idle":"2022-07-22T18:05:08.876031Z","shell.execute_reply.started":"2022-07-22T18:05:08.388034Z","shell.execute_reply":"2022-07-22T18:05:08.875104Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# MODEL TESTING","metadata":{}},{"cell_type":"code","source":"sample = random.choice(test_data['File Path'])\n\ncategory = sample.split('/')[-3]\ntrue = ''\nif category == 'COVID':\n    true = 'COVID'\nelif category == 'Viral Pneumonia':\n    true = 'Viral Pneumonia'\nelse:\n    true = 'Normal'\n\nprint(f'True value is : {true}')\n    \nimage = load_img(sample, target_size=(224, 224))\nimg = img_to_array(image)\nimg = img.reshape((1, 224, 224, 3))\n\nresult = model.predict(img)\nresult = np.argmax(result, axis=-1)\nprint('Prediction is:')\nif result == 0:\n    print(\"Normal\")\nelif result == 1:\n    print(\"Viral Pneumonia\")\nelse:\n    print(\"COVID +\")\n    \nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:12:44.442881Z","iopub.execute_input":"2022-07-22T18:12:44.443309Z","iopub.status.idle":"2022-07-22T18:12:45.105370Z","shell.execute_reply.started":"2022-07-22T18:12:44.443273Z","shell.execute_reply":"2022-07-22T18:12:45.104442Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}